{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roles and Responsinility\n",
    "\n",
    "My name is Pravin Piske, I did my eng from AISSMS COE Pune, \n",
    "\n",
    "I have more than 4 yrs exp in the field of Data science, \n",
    "\n",
    "I used python for building models, SQL for fetching data, Machine learning, GCP, big query, \n",
    "\n",
    "My roles and my responsibilities are Fetching data, data cleaning, data processing, feature engineering and feature selection, \n",
    "model training, model building and validation, hyperparameter tuning, feature scaling.\n",
    "\n",
    "I joined the EXL in 16 oct 2023\n",
    "\n",
    "Apart from that I am a team player who always enjoy to work in team, always follow kaizen, its japanese term it means continuous \n",
    "improvement, I always improve my self, I have never give up attitude, I always see positive in every critical situation that\n",
    "give me inspiration to complete difficult task, and I am confident man. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. **Data Gathering**:\n",
    "   - Extract data from Snowflake to S3 (storage).\n",
    "   - Load data from S3 to Databricks (processing and analysis platform).\n",
    "\n",
    "2. **Data Cleaning**:\n",
    "   a. Handle Missing Values:\n",
    "      - Identify missing values.\n",
    "      - Decide how to handle missing values: fill with mean, median, mode, or drop rows/columns.\n",
    "      - Replace with the mean and zeros (mean for continuous, mode for categorical).\n",
    "    \n",
    "   b. Handle Outliers:\n",
    "      - Detect and analyze outliers.\n",
    "      - Choose a strategy to deal with outliers: replace with mean/median, clip, or drop.\n",
    "        \n",
    "   c. Handle Duplicate Values:\n",
    "      - Identify and handle duplicate records.\n",
    "\n",
    "3. **Data Processing**:\n",
    "   - Feature-specific processing:\n",
    "      - Impute missing values based on data type (mean for continuous, mode for categorical).\n",
    "   - Encoding:\n",
    "      - Label Encoding (for ordinal data).\n",
    "      - One-Hot Encoding (for nominal data).\n",
    "   - Feature Scaling:\n",
    "      - Use Min-Max Scaler or Standard Scaler to normalize features.\n",
    "\n",
    "4. **Feature Engineering / Feature Selection**:\n",
    "   - Explore and analyze relationships between features using:\n",
    "      - Correlation plot.\n",
    "      - Chi-squared test.\n",
    "      - Feature importance from tree-based models.\n",
    "      - ANOVA test (for categorical target).\n",
    "      - T-test (for numerical target).\n",
    "      - Variance threshold.\n",
    "      - Information gain.\n",
    "      - Domain knowledge.\n",
    "   - Dimensionality reduction (if needed):\n",
    "      - PCA (Principal Component Analysis).\n",
    "\n",
    "5. **Multicollinearity and Overfitting**:\n",
    "   - Check for multicollinearity using Variance Inflation Factor (VIF).\n",
    "   - Implement techniques to reduce overfitting:\n",
    "      - Ridge and Lasso regularization.\n",
    "      - Cross-validation.\n",
    "      - Bagging and boosting methods.\n",
    "      - Removing outliers (if necessary).\n",
    "\n",
    "6. **Imbalanced Dataset Handling**:\n",
    "   - Employ techniques to handle imbalanced datasets:\n",
    "      - SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "      - Downsampling.\n",
    "      - Oversampling.\n",
    "      - Adjust precision-recall curve threshold for optimal F1 score.\n",
    "\n",
    "7. **Model Building**:\n",
    "   - Select a variety of classification algorithms to build initial models:\n",
    "      - Logistic Regression.\n",
    "      - K-Nearest Neighbors (KNN).\n",
    "      - Decision Trees.\n",
    "      - Random Forest.\n",
    "      - XGBoost.\n",
    "      - Support Vector Machine (SVM).\n",
    "      - Naive Bayes.\n",
    "\n",
    "8. **Cross-Validation**:\n",
    "   - Implement k-fold cross-validation to assess model performance robustly.\n",
    "\n",
    "9. **Model Tuning**:\n",
    "   - Tune hyperparameters of each algorithm:\n",
    "      - GridSearch CV.\n",
    "      - RandomSearch CV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b22df",
   "metadata": {},
   "source": [
    "### 1.Data cleaning and Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ca585",
   "metadata": {},
   "source": [
    "### A.Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Drop the row records only when you have huge datasets but for small datset this will not be recomanded to do\n",
    "\n",
    "we can also set thresh to drop columns in this case\n",
    "\n",
    "not recommanded bcz you will loose important information which is present in another columns.\n",
    "\n",
    "2.Impute:\n",
    "    a.Univariate: Using some statistics method\n",
    "        i.Numerical:\n",
    "            mean, median or by any random values\n",
    "        mean:\n",
    "            continous data \n",
    "            and only have few missing values and \n",
    "            when data has less outliers \n",
    "            when data is normal distributed\n",
    "            \n",
    "        median:\n",
    "            continuous data if you have outliers \n",
    "            when data has not normally distributed\n",
    "        Zeros:\n",
    "            \n",
    "        ii.Categorical:\n",
    "            mode, 'others' word with null value\n",
    "            \n",
    "    Multivariate: create a seprate model to handle missing values, Reuqired more time only have smaller dataset do that \n",
    "        otherwise skip that\n",
    "        KNN imputor\n",
    "        Iterator imputer\n",
    "    \n",
    "My Approch:\n",
    "    1.Few no of missing values and only contains 7-8 columns that time *drop the features\n",
    "    2.few no of missing values so replaced with *median bcz data was skewed and outliers present\n",
    "    3.Very less no of missing values so replaced with *mean bcz data is not is normally distributed outliers present\n",
    "    4.one of columns consist of high no of missing values so directly droped that columns which is not imp\n",
    "    5.Replace with zeros bcz its good technique instead of synthetic or fake data and also\n",
    "      we had less missing values that time so replaced with zeros\n",
    "        \n",
    "for zero:\n",
    "    In some cases BMI high, Sugar BP also high\n",
    "    If we calculate mean/median in that case your mean of BP is 90 but other feature are BMI high, sugar high so this is not \n",
    "    make sense to replace with the synthetic data and random forest work well with sparse data so that is why we replaced \n",
    "    with zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf18d959",
   "metadata": {},
   "source": [
    "### B.Handle Outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "Treatment of outliers:\n",
    "    1. Dropping the outliers not good technique\n",
    "    2. replacing the values with some standard statistical values(mean,median,mode) >> Median is best technqiue\n",
    "    statisticalcal computation\n",
    "    3. Thresold split\n",
    "    4. Normalization\n",
    "        a. min-max scaling\n",
    "        b. standardization\n",
    "        c. robust scaling\n",
    "    5. Transformation:\n",
    "        a. log-transform\n",
    "        b. sqrt transform\n",
    "        c. cbrt transform\n",
    "        d. box-cox transform\n",
    "        e. reciprocal transform\n",
    "\n",
    "My approch:\n",
    "    1.Replace with median\n",
    "    2.Apply normalisation and transformation technique\n",
    "    \n",
    "# Duplicates item we can directly drop the duplicates rows and columns\n",
    "# Changing datatypes all into int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795f830",
   "metadata": {},
   "source": [
    "### C.Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f29ae30",
   "metadata": {},
   "source": [
    "Label Encoding (for ordinal data):\n",
    "    1.Use this when data has some order but in practical we can prefer to use when have order we can use if else is good when\n",
    "    data has some order\n",
    "    2.categorical data with 2 categories like gender use label encoding here\n",
    "    \n",
    "One-Hot Encoding (for nominal data):\n",
    "    2.when we have more than 1 category and if you want to train the model with this use OHE always bcz its saves exploded\n",
    "    category well\n",
    "    \n",
    "Get Dummies:\n",
    "    use when we are performing EDA \n",
    "    \n",
    "My approch also same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.Feature Scaling:\n",
    "    Use Min-Max Scaler or Standard Scaler to normalize features.\n",
    "    Time series case - Before spliting\n",
    "    Machine learning - After spliting is best approch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a654a5",
   "metadata": {},
   "source": [
    "### Imbalance data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239deb7",
   "metadata": {},
   "source": [
    "The accuracy of a classifier is the total number of correct predictions by the classifier divided by the total number of \n",
    "predictions. This may be good enough for a well-balanced class but not ideal for the imbalanced class problem. \n",
    "\n",
    "The other metrics such as precision is the measure of how accurate the classifier’s prediction of a specific class and recall \n",
    "is the measure of the classifier’s ability to identify a class.\n",
    "\n",
    "Set a threshold on the basis of business and domain knowldge and gridesearch CV\n",
    "\n",
    "calculate the probabilities of 1 class and by using grid search get the optimal threshold set that threshold PR curve \n",
    "and see f1 score now \n",
    "\n",
    "If the F1 score with the optimal threshold is high, it indicates that the model is performing well in terms of balancing \n",
    "precision and recall for the positive class.\n",
    "\n",
    "Imbalance data means - 9/10 No heart diseses ||| 1/10 say having disese here negative class observed more so in that case\n",
    "\n",
    "ROC AUC curve gives 0.9 accuracy which is not reliable so use PR is better when we want treat positive class with more weight\n",
    "\n",
    "If there are large number of 0 in model means we are less intereseted in predicting class 0 correctly i.e high true negatives\n",
    "\n",
    "The PR curve is concerned with the correct prediction of the minority class (class 1), which includes both true positives and \n",
    "false negatives. \n",
    "\n",
    "To find the optimal threshold that balances precision and recall for the positive class, you calculate the probabilities for the\n",
    "positive class and then determine the threshold that maximizes the F1 score, AUC-PR, or any other relevant metric for your \n",
    "problem.\n",
    "\n",
    "when dealing with imbalanced data, especially in binary classification, it's common to focus on calculating the probabilities \n",
    "for the positive class (class 1) when determining the optimal threshold. This is because the positive class is often the\n",
    "minority class of interest, and you want to ensure that you set the threshold in a way that maximizes the balance between \n",
    "precision and recall for that positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "If our data is imbalance use PR-AUC curve and F1 score\n",
    "\n",
    "Imbalance data means - 9/10 No heart diseses ||| 1/10 say having disese here negative class observed more so in that case\n",
    "\n",
    "ROC AUC curve gives 0.9 accuracy which is not reliable so use PR is better when we want treat positive class with more weight\n",
    "\n",
    "If there are large number of 0 in model means we are less intereseted in predicting class 0 correctly i.e high true negatives\n",
    "\n",
    "The PR curve is concerned with the correct prediction of the minority class (class 1), which includes both true positives and \n",
    "false negatives. \n",
    "\n",
    "It aims to balance precision and recall for the positive class.\n",
    "\n",
    "The calculations for the PR curve do not involve true negatives. \n",
    "\n",
    "This is because the PR curve is primarily focused on evaluating the model's performance in terms of the minority class (class 1)\n",
    "\n",
    "True negatives are associated with the majority class (class 0), which is not the primary focus of the PR curve.\n",
    "\n",
    "In medical datasets, it's common to have imbalanced classes. For instance, in disease detection, the number of healthy patients \n",
    "(negative class) might greatly outnumber the number of patients with the disease (positive class). \n",
    "\n",
    "This imbalance can make it challenging to evaluate a model's performance accurately, as accuracy alone might be misleading due \n",
    "to the dominance of the majority class.\n",
    "\n",
    "**Precision-Recall Curve**:\n",
    "    \n",
    "1. **Focus on the Positive Class**: In medical scenarios, you're often more concerned about correctly identifying the positive \n",
    "    class (disease) than the negative class (healthy). # The PR curve focuses on the performance of the positive class.\n",
    "\n",
    "2. **Threshold Variation**: The PR curve considers different classification thresholds for determining positive and negative\n",
    "    predictions. By varying the threshold, you explore how precision and recall change.\n",
    "\n",
    "3. **Precision and Recall Calculation**: For each threshold, calculate precision and recall using the true positive (TP), false \n",
    "    positive (FP), and false negative (FN) counts. Precision (TP / (TP + FP)) tells you how many of the predicted positive cases\n",
    "    are actually positive, while recall (TP / (TP + FN)) tells you how many actual positive cases were predicted as positive.\n",
    "\n",
    "4. **Balancing Precision and Recall**: The PR curve visually shows the trade-off between precision and recall. It helps you\n",
    "    choose a threshold that balances the importance of correctly identifying true positives (recall) while minimizing false \n",
    "    positives (improving precision).\n",
    "\n",
    "5. **Area Under the Curve (AUC-PR)**: The AUC-PR quantifies the overall performance of the model across different thresholds.\n",
    "    A higher AUC-PR indicates better performance, especially when dealing with imbalanced data.\n",
    "    \n",
    "**F1 Score**:\n",
    "    \n",
    "In many cases, increasing precision can lead to a decrease in recall, and vice versa.\n",
    "For example, setting a high threshold for positive predictions might increase precision but decrease recall. Conversely, \n",
    "setting a low threshold might increase recall but decrease precision.\n",
    "\n",
    "The harmonic mean is a measure of central tendency that gives more weight to lower values. In the context\n",
    "of the F1 score, the harmonic mean of precision and recall is used to find a balance between these two metrics. This is \n",
    "particularly useful when dealing with imbalanced datasets, where one metric might be significantly higher than the other.\n",
    "\n",
    "1. **Balancing Precision and Recall**: The F1 score considers the trade-off between precision and recall by calculating their \n",
    "    harmonic mean. It's a suitable metric when you want to balance the importance of minimizing false positives and false \n",
    "    negatives.\n",
    "\n",
    "2. **Interpretability**: The F1 score condenses the model's performance into a single value, making it easy to compare models \n",
    "    and assess their overall effectiveness.\n",
    "\n",
    "In the context of imbalanced medical data, both the PR curve and the F1 score provide valuable insights. The PR curve helps you \n",
    "visualize how well your model performs at different thresholds, allowing you to choose a threshold that meets your priorities.\n",
    "The F1 score provides a balanced measure of your model's precision and recall, summarizing its performance in a single value. \n",
    "Together, these tools help you evaluate and improve your model's performance when dealing with imbalanced medical data.\n",
    "\n",
    "So, while it's not necessary to calculate the F1 score first, it's common to use the Precision-Recall curve as a visualization \n",
    "tool to guide your threshold selection, and then calculate the F1 score to provide a concise performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46f3a7",
   "metadata": {},
   "source": [
    "### How model focus on Positive prediction for medical imbalanced datset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944b62e",
   "metadata": {},
   "source": [
    "When dealing with imbalanced datasets, such as medical disease data where the number of positive cases is much smaller than negative cases, you may want to focus on positive prediction probability to effectively evaluate and improve the performance of your machine learning model. However, this doesn't mean you should exclusively focus on positive prediction probability; rather, you should consider several strategies:\n",
    "\n",
    "1. **Positive Prediction Probability Thresholding**:\n",
    "   - In imbalanced datasets, it's common to set a lower probability threshold for classifying instances as positive. This helps in capturing more of the positive cases (higher recall), even if it results in more false positives (lower precision).\n",
    "   - You can experiment with different threshold values to find a balance that aligns with your goals and the specific requirements of your application.\n",
    "\n",
    "2. **Precision-Recall Curve Analysis**:\n",
    "   - Create a Precision-Recall (PR) curve, as discussed earlier, by varying the probability threshold. This curve provides insights into how precision and recall trade off at different thresholds.\n",
    "   - Analyze the curve to identify an operating point that suits your needs. In imbalanced datasets, you might prioritize higher recall to ensure that you capture a significant portion of the positive cases.\n",
    "\n",
    "3. **F1 Score and Other Metrics**:\n",
    "   - Consider using metrics that combine precision and recall, such as the F1 score, which provides a single value that balances both measures.\n",
    "   - Other metrics like the area under the PR curve (AUC-PR) can also be informative when assessing model performance on imbalanced data.\n",
    "\n",
    "4. **Resampling Techniques**:\n",
    "   - Explore resampling techniques, such as oversampling the minority class (positive class) or undersampling the majority class (negative class), to balance the dataset. This can help improve the model's ability to learn from the positive class.\n",
    "\n",
    "5. **Cost-sensitive Learning**:\n",
    "   - In some cases, you can assign different misclassification costs to different classes. This is known as cost-sensitive learning. It allows you to explicitly account for the imbalanced nature of the dataset when training the model.\n",
    "\n",
    "6. **Ensemble Methods**:\n",
    "   - Consider using ensemble methods like Random Forests or Gradient Boosting, which can handle imbalanced data more effectively by combining multiple models.\n",
    "\n",
    "7. **Feature Engineering and Model Selection**:\n",
    "   - Carefully select features and models that are well-suited to imbalanced datasets.\n",
    "   - Feature engineering techniques, such as creating informative synthetic features or transforming existing ones, can help.\n",
    "\n",
    "8. **Cross-Validation**:\n",
    "   - Use techniques like stratified cross-validation to ensure that each fold of your dataset maintains the same class distribution as the original dataset. This can provide a more accurate estimate of your model's performance.\n",
    "\n",
    "In summary, while focusing on positive prediction probability is important in imbalanced datasets for medical disease data and similar scenarios, it should be part of a broader strategy that includes threshold tuning, evaluation metrics, resampling techniques, and model selection to address the challenges posed by imbalanced data effectively. The choice of strategy depends on your specific goals and the consequences of false positives and false negatives in your application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8f70c",
   "metadata": {},
   "source": [
    "### Explain this entire process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfbeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.For medical problem 0 are more and 1 are less so we need to give more focus on 1 i.e positive preidctions\n",
    "\n",
    "2.For that we have to plot PR curve and F1 score and PR curve only focus on positive prediction\n",
    "\n",
    "3.First calculate the probabilities by setting up the lower threshold for positive samples to cover more positive values\n",
    "(It is ok if they are FP)\n",
    "\n",
    "4.Then plot PR curve and calculate the F1 score if F1 score is high means there is good balance between precision and recall\n",
    "\n",
    "5.F1 score has harmonic mean so it gives more weightage to lower values in medical data positive prediction having lower values\n",
    "it gives the well balance between precision and recall values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
